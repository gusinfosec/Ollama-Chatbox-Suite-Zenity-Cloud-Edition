<p align="center">
  <img src="assets/ollama-suite-banner.png" alt="Ollama Chatbox Suite â€“ Zenity & Cloud Edition" width="100%" />
</p>

<h1 align="center">ğŸ’¬ Ollama Chatbox Suite â€“ Zenity & Cloud Edition</h1>
<p align="center">
  <strong>A multi-interface AI suite for Ollama built by <a href="https://www.cyberglobal.ai">Cyber Global Technologies LLC</a>.</strong><br>
  Zenity GUI â€¢ Terminal Chat â€¢ Web Mini Chat â€” all in one lightweight suite for Linux.<br>
  <a href="https://ko-fi.com/gusinfosec">Ko-fi</a> â€¢ <a href="https://github.com/gusinfosec">GitHub</a> â€¢ <a href="https://www.linkedin.com/in/gusinfosec">LinkedIn</a>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/status-active-brightgreen" alt="Status: active" />
  <img src="https://img.shields.io/badge/license-MIT-blue" alt="License: MIT" />
  <img src="https://img.shields.io/badge/built%20for-Linux-lightgrey" alt="Built for: Linux" />
</p>

---

## ğŸ§© Overview
**Ollama Chatbox Suite** unifies AI interaction on Linux through three interfaces:  
- A **Zenity-based GUI model selector** for quick workflows  
- A **colorized terminal chat client** with file and model support  
- A **lightweight web mini chat** with gradient visuals and local hosting  

Switch between local and cloud models such as **Qwen**, **GPT-OSS**, and **Deepseek** with one consistent experience.  
Part of the **Cyber Global Technologies LLC** ecosystem â€” secure, practical, and human-focused AI tools for professionals and teams.

---

## ğŸš€ Features

### ğŸªŸ Zenity GUI Chat
- Pop-up model selector with multi-model support  
- Seamless integration with local Ollama models  
- Optional license verification for commercial users  

### ğŸ§  Terminal Chat (CLI)
- Interactive model menu with icons and colors  
- File attachment support (`:file <path>`)  
- Restart or switch model without closing  

### ğŸ–¥ï¸ Web Mini Chat
- Modern UI with gradient glow and branding  
- File/image upload and model selection  
- Lightweight â€” runs on a local Python server  

---

## ğŸ§© Supported Models
- `qwen3-vl`  
- `qwen3-coder`  
- `TinyLlama`  
- `gpt-oss`  
- `qwen3-vl:235b-cloud`

---

## ğŸ› ï¸ Setup

### 1ï¸âƒ£ Install Ollama
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Start the service:
```bash
ollama serve &
```

(Optional â€“ make persistent)
```bash
sudo systemctl enable ollama
sudo systemctl start ollama
```

---

### 2ï¸âƒ£ Terminal Chat Installation
```bash
chmod +x ollama-chat.sh
./ollama-chat.sh
```

(Optional â€“ make global)
```bash
mv ollama-chat.sh ~/bin/chat
```

---

### 3ï¸âƒ£ Web Mini Chat Launch
```bash
python3 -m http.server 11435
```

Then visit:
```
http://localhost:11435/ollama-mini.html
```

ğŸŸ¢ Works automatically with `ollama serve` on port `11434`.

---

## ğŸ§± Folder Structure
```
ollama-chatbox-suite/
â”œâ”€â”€ ollama-chat.sh
â”œâ”€â”€ ollama-mini.html
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ zenity-model-selector.png
â”‚   â”œâ”€â”€ terminal-response.png
â”‚   â””â”€â”€ mini-chat-cloud.png
â””â”€â”€ README.md
```

---

## ğŸª™ Editions
| Edition | Description | Price |
|----------|--------------|------:|
| **Pro Edition** | Full suite (Web + Zenity + Terminal) | **$29** |
| **Commercial Bundle** | Includes Compliance AI Preview | **$49** |

Explore more tools at  
[â˜• Ko-fi.com/gusinfosec](https://ko-fi.com/gusinfosec)

---

## âš–ï¸ License
MIT License Â© 2025 **Cyber Global Technologies LLC**  
Use permitted for personal and educational projects.  
Commercial licensing available via [Ko-fi](https://ko-fi.com/gusinfosec).

---

<p align="center"><strong>Part of the Cyber Global Technologies ecosystem â€” secure, practical, human-focused tools for professionals and teams.</strong></p>
